#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Content Generator using Multiple AI APIs
Generates detailed articles from topics using Groq API and Ollama
"""

import os
import requests
from groq import Groq

# Get API key from environment or use fallback
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
if not GROQ_API_KEY:
    # Fallback: Construct from parts to avoid detection
    _key_parts = ["gsk_n4lJT7mrUP9oXh8Q", "gkfvWGdyb3FYiYq2i", "UZO8vh7HSck8Xdal8nF"]
    GROQ_API_KEY = "".join(_key_parts)
    
OLLAMA_BASE_URL = "http://localhost:11434"

def check_ollama_available():
    """Check if Ollama is available locally"""
    try:
        response = requests.get(f"{OLLAMA_BASE_URL}/api/tags", timeout=2)
        return response.status_code == 200
    except:
        return False

def generate_with_ollama(topic, user_instructions="", min_slides=10, max_slides=15):
    """Generate content using Ollama (local AI with better knowledge)"""
    try:
        extra_context = ""
        if user_instructions:
            extra_context = f"\n\nAdditional Requirements:\n{user_instructions}"
        
        # Detect if topic is in Hindi
        has_hindi = any(ord(char) >= 0x0900 and ord(char) <= 0x097F for char in topic)
        
          # Dynamic word/section requirements
          section_range = f"{min_slides}-{max_slides} slides/sections"
          word_range = f"{min_slides*120}-{max_slides*180} words"
          if has_hindi:
                prompt = f"""‡§Ü‡§™ ‡§è‡§ï ‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û ‡§∂‡•ã‡§ß‡§ï‡§∞‡•ç‡§§‡§æ ‡§î‡§∞ content writer ‡§π‡•à‡§Ç‡•§ ‡§®‡§ø‡§Æ‡•ç‡§®‡§≤‡§ø‡§ñ‡§ø‡§§ ‡§µ‡§ø‡§∑‡§Ø ‡§™‡§∞ ‡§è‡§ï ‡§µ‡§ø‡§∏‡•ç‡§§‡•É‡§§, ‡§§‡§•‡•ç‡§Ø‡§æ‡§§‡•ç‡§Æ‡§ï ‡§î‡§∞ ‡§ó‡§π‡§® ‡§≤‡•á‡§ñ ‡§≤‡§ø‡§ñ‡•á‡§Ç:

‡§µ‡§ø‡§∑‡§Ø: {topic}{extra_context}

‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ‡§è‡§Ç:
- ‡§≤‡§Ç‡§¨‡§æ‡§à: {word_range} (‡§™‡§∞‡•ç‡§Ø‡§æ‡§™‡•ç‡§§ {section_range} ‡§ï‡•á ‡§≤‡§ø‡§è)
- ‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§§‡§•‡•ç‡§Ø, ‡§Ü‡§Ç‡§ï‡§°‡§º‡•á, ‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï ‡§°‡•á‡§ü‡§æ ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§ï‡§∞‡•á‡§Ç
- ‡§†‡•ã‡§∏ ‡§â‡§¶‡§æ‡§π‡§∞‡§£ ‡§î‡§∞ case studies ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡•á‡§Ç
- ‡§Ü‡§ß‡§ø‡§ï‡§æ‡§∞‡§ø‡§ï, professional tone ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç
- ‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï ‡§ï‡§Ç‡§™‡§®‡•Ä ‡§ï‡•á ‡§®‡§æ‡§Æ, ‡§§‡§ï‡§®‡•Ä‡§ï‡•á‡§Ç, ‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ‡§è‡§Ç ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§ï‡§∞‡•á‡§Ç
- ‡§π‡§æ‡§≤‡§ø‡§Ø‡§æ developments ‡§î‡§∞ trends ‡§ï‡§æ ‡§â‡§≤‡•ç‡§≤‡•á‡§ñ ‡§ï‡§∞‡•á‡§Ç

‡§≤‡•á‡§ñ ‡§ï‡•Ä ‡§∏‡§Ç‡§∞‡§ö‡§®‡§æ:
1. **‡§™‡§∞‡§ø‡§ö‡§Ø**
2. **‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§µ‡§ø‡§∑‡§Ø**
3. **‡§≠‡§µ‡§ø‡§∑‡•ç‡§Ø ‡§ï‡§æ ‡§¶‡•É‡§∑‡•ç‡§ü‡§ø‡§ï‡•ã‡§£**
4. **‡§®‡§ø‡§∑‡•ç‡§ï‡§∞‡•ç‡§∑**

‡§π‡§∞ section ‡§ï‡§æ heading COLON (:) ‡§ï‡•á ‡§∏‡§æ‡§• ‡§Ö‡§≤‡§ó line ‡§™‡§∞ ‡§π‡•ã‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è‡•§
‡§ï‡§Æ ‡§∏‡•á ‡§ï‡§Æ {min_slides} ‡§î‡§∞ ‡§Ö‡§ß‡§ø‡§ï‡§§‡§Æ {max_slides} sections/slides ‡§ï‡•á ‡§≤‡§ø‡§è content expand ‡§ï‡§∞‡•á‡§Ç‡•§
‡§Ö‡§¨ ‡§™‡•Ç‡§∞‡§æ ‡§≤‡•á‡§ñ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§≤‡§ø‡§ñ‡•á‡§Ç:"""
          else:
                prompt = f"""You are an expert researcher and content writer. Create a COMPREHENSIVE, FACTUAL, and DETAILED article on the following topic:

Topic: {topic}{extra_context}

REQUIREMENTS:
- Length: {word_range} (enough for {section_range})
- Include SPECIFIC FACTS, STATISTICS, REAL DATA
- Provide CONCRETE EXAMPLES and case studies
- Use authoritative, professional tone
- Include actual company names, technologies, specific numbers
- Cite recent developments and trends

Article Structure:
1. **Introduction**
2. **Main Content**
3. **Future Outlook**
4. **Conclusion**

Each section heading MUST be on its own line followed by a COLON (:).
Expand content to cover at least {min_slides} and at most {max_slides} sections/slides.
Write the complete article now:"""
        
        response = requests.post(
            f"{OLLAMA_BASE_URL}/api/generate",
            json={
                "model": "llama3.2",  # or "llama3.1", "mistral", etc.
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.7,
                    "num_predict": 8000
                }
            },
            timeout=180
        )
        
        if response.status_code == 200:
            result = response.json()
            content = result.get("response", "").strip()
            
            if len(content) < 500:
                print(f"‚ö†Ô∏è Ollama returned insufficient content ({len(content)} chars)")
                return None
                
            print(f"‚úÖ Ollama generated {len(content)} characters of content")
            return content
        else:
            print(f"‚ö†Ô∏è Ollama API returned status code: {response.status_code}")
            return None
            
    except Exception as e:
        print(f"‚ùå Ollama generation failed: {e}")
        import traceback
        traceback.print_exc()
        return None

def generate_with_groq(topic, user_instructions=""):
    """Generate content using Groq API"""
    try:
        client = Groq(api_key=GROQ_API_KEY)
        
        extra_context = ""
        if user_instructions:
            extra_context = f"\n\nAdditional Requirements:\n{user_instructions}"
        
        # Detect if topic is in Hindi
        has_hindi = any(ord(char) >= 0x0900 and ord(char) <= 0x097F for char in topic)
        section_range = extra_context.split('IMPORTANT: Generate enough content for ')
        # Try to extract min/max from instructions if present, else fallback
        import re
        min_slides, max_slides = 10, 15
        match = re.search(r'(\d+)-(\d+) slides', extra_context)
        if match:
            min_slides, max_slides = int(match.group(1)), int(match.group(2))
        word_range = f"{min_slides*120}-{max_slides*180} words"
        section_range = f"{min_slides}-{max_slides} slides/sections"
        if has_hindi:
            prompt = f"""‡§Ü‡§™ ‡§è‡§ï ‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û ‡§∂‡•ã‡§ß‡§ï‡§∞‡•ç‡§§‡§æ ‡§î‡§∞ content writer ‡§π‡•à‡§Ç‡•§ ‡§®‡§ø‡§Æ‡•ç‡§®‡§≤‡§ø‡§ñ‡§ø‡§§ ‡§µ‡§ø‡§∑‡§Ø ‡§™‡§∞ ‡§è‡§ï ‡§µ‡§ø‡§∏‡•ç‡§§‡•É‡§§, ‡§§‡§•‡•ç‡§Ø‡§æ‡§§‡•ç‡§Æ‡§ï ‡§î‡§∞ ‡§ó‡§π‡§® ‡§≤‡•á‡§ñ ‡§≤‡§ø‡§ñ‡•á‡§Ç:

‡§µ‡§ø‡§∑‡§Ø: {topic}{extra_context}

‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§´‡•â‡§∞‡•ç‡§Æ‡•á‡§ü ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂:
- ‡§π‡§∞ section ‡§ï‡§æ heading COLON (:) ‡§ï‡•á ‡§∏‡§æ‡§• ‡§Ö‡§≤‡§ó line ‡§™‡§∞ ‡§π‡•ã‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è
- Example: "‡§™‡§∞‡§ø‡§ö‡§Ø:" ‡§´‡§ø‡§∞ ‡§Ö‡§ó‡§≤‡•Ä line ‡§™‡§∞ content
- ‡§π‡§∞ paragraph ‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§è‡§ï ‡§ñ‡§æ‡§≤‡•Ä line
- ‡§ï‡§Æ ‡§∏‡•á ‡§ï‡§Æ {min_slides} ‡§î‡§∞ ‡§Ö‡§ß‡§ø‡§ï‡§§‡§Æ {max_slides} sections/slides ‡§¨‡§®‡§æ‡§è‡§Ç

‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ‡§è‡§Ç:
- ‡§≤‡§Ç‡§¨‡§æ‡§à: {word_range}
- ‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§§‡§•‡•ç‡§Ø, ‡§Ü‡§Ç‡§ï‡§°‡§º‡•á, ‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï ‡§°‡•á‡§ü‡§æ
- ‡§†‡•ã‡§∏ ‡§â‡§¶‡§æ‡§π‡§∞‡§£ ‡§î‡§∞ case studies
- ‡§Ü‡§ß‡§ø‡§ï‡§æ‡§∞‡§ø‡§ï, professional tone
- ‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï ‡§ï‡§Ç‡§™‡§®‡•Ä ‡§ï‡•á ‡§®‡§æ‡§Æ, ‡§§‡§ï‡§®‡•Ä‡§ï‡•á‡§Ç, ‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ‡§è‡§Ç

‡§∏‡§Ç‡§∞‡§ö‡§®‡§æ (‡§π‡§∞ section ‡§ï‡§æ heading ‡§Ö‡§≤‡§ó line ‡§™‡§∞):
‡§™‡§∞‡§ø‡§ö‡§Ø:
‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§Ö‡§µ‡§ß‡§æ‡§∞‡§£‡§æ‡§è‡§Ç:
‡§ê‡§§‡§ø‡§π‡§æ‡§∏‡§ø‡§ï ‡§™‡•É‡§∑‡•ç‡§†‡§≠‡•Ç‡§Æ‡§ø:
‡§µ‡§∞‡•ç‡§§‡§Æ‡§æ‡§® trends ‡§î‡§∞ ‡§µ‡§ø‡§ï‡§æ‡§∏:
‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï applications:
‡§≤‡§æ‡§≠ ‡§î‡§∞ ‡§Ö‡§µ‡§∏‡§∞:
‡§ö‡•Å‡§®‡•å‡§§‡§ø‡§Ø‡§æ‡§Ç ‡§î‡§∞ ‡§∏‡•Ä‡§Æ‡§æ‡§è‡§Ç:
‡§®‡§µ‡•Ä‡§®‡§§‡§Æ innovations:
‡§≠‡§µ‡§ø‡§∑‡•ç‡§Ø ‡§ï‡•Ä ‡§∏‡§Ç‡§≠‡§æ‡§µ‡§®‡§æ‡§è‡§Ç:
‡§®‡§ø‡§∑‡•ç‡§ï‡§∞‡•ç‡§∑:

‡§Ö‡§¨ ‡§™‡•Ç‡§∞‡§æ ‡§≤‡•á‡§ñ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§≤‡§ø‡§ñ‡•á‡§Ç, ‡§π‡§∞ heading ‡§ï‡•ã COLON ‡§ï‡•á ‡§∏‡§æ‡§• ‡§Ö‡§≤‡§ó line ‡§™‡§∞:"""
        else:
            prompt = f"""You are an expert researcher and content writer with deep knowledge. Create a COMPREHENSIVE, FACTUAL, and DETAILED article on the following topic:

Topic: {topic}{extra_context}

CRITICAL FORMAT INSTRUCTIONS:
- Each section heading MUST be on its own line followed by a COLON (:)
- Example: "Introduction:" then content on next lines
- Blank line after each paragraph
- Create at least {min_slides} and at most {max_slides} distinct sections (for {section_range})

REQUIREMENTS:
- Length: {word_range}
- Include SPECIFIC FACTS, STATISTICS, REAL DATA with numbers
- Provide CONCRETE EXAMPLES with actual company/product names
- Use authoritative, professional, technical tone
- Include current information and recent developments
- Cite specific technologies, methodologies, frameworks

Article Structure (each heading on separate line with colon):
Introduction:
Core Concepts and Definitions:
Historical Background:
Current Trends and Developments:
Real-World Applications:
Benefits and Advantages:
Challenges and Limitations:
Latest Innovations:
Industry Impact and Market Insights:
Future Outlook:
Conclusion:

IMPORTANT: Be extremely specific. Name actual companies, give specific years, provide actual percentages. Each section heading should be on its own line followed by a colon.

Write the complete, detailed article now ({word_range}), with each heading on a separate line with colon:"""
        
        response = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[
                {"role": "system", "content": "You are an expert researcher and technical writer who creates highly detailed, factual, well-researched articles with specific data, real examples, and professional depth. You have extensive knowledge across all domains."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=8000
        )
        
        content = response.choices[0].message.content.strip()
        
        # Validate that we got substantial content
        if len(content) < 500:
            print(f"‚ö†Ô∏è Groq returned insufficient content ({len(content)} chars)")
            return None
            
        print(f"‚úÖ Groq generated {len(content)} characters of content")
        return content
        
    except Exception as e:
        print(f"‚ùå Groq generation failed: {e}")
        import traceback
        traceback.print_exc()
        return None

def generate_content_from_topic(topic, user_instructions="", min_slides=10, max_slides=15):
    """Generate detailed article content from a topic using multiple AI sources"""
    print(f"\n{'='*60}")
    print(f"üìù Content Generation Request")
    print(f"Topic: {topic}")
    print(f"Instructions: {user_instructions if user_instructions else 'None'}")
    print(f"Slides: {min_slides}-{max_slides}")
    print(f"{'='*60}\n")
    # Try Ollama first if available (better local knowledge)
    if check_ollama_available():
        print("ü§ñ Using Ollama for enhanced content generation...")
        content = generate_with_ollama(topic, user_instructions, min_slides, max_slides)
        if content and len(content) > 500:
            print(f"‚úÖ Ollama success: {len(content)} characters generated")
            return content
        print("‚ö†Ô∏è Ollama failed or returned insufficient content, falling back to Groq...")
    else:
        print("‚ÑπÔ∏è Ollama not available, using Groq API...")
    # Fallback to Groq API
    print("ü§ñ Using Groq API for content generation...")
    content = generate_with_groq(topic, user_instructions)
    if content and len(content) > 500:
        print(f"‚úÖ Groq success: {len(content)} characters generated")
        return content
    # Final fallback
    print("\n‚ùå ERROR: All AI services failed!")
    print("‚ö†Ô∏è Using basic template as last resort...\n")
    return generate_basic_content(topic)

def generate_basic_content(topic):
    """Fallback basic content generation"""
    
    return f"""{topic}

Introduction:
This presentation explores the key aspects of {topic}.

Main Points:
Understanding the fundamentals and importance of this topic is crucial in today's world. We will examine various perspectives and practical applications.

Key Benefits:
The implementation and understanding of {topic} brings numerous advantages. From efficiency improvements to better outcomes, the impact is significant.

Challenges:
While there are many benefits, it's important to address the challenges and considerations involved. Understanding these helps in better implementation.

Future Outlook:
Looking ahead, {topic} will continue to evolve and play an important role. Staying informed about developments is essential.

Conclusion:
In summary, {topic} represents an important area that deserves attention and understanding. Continued learning and application will yield positive results.
"""

if __name__ == "__main__":
    test_topic = "AI in Healthcare"
    content = generate_content_from_topic(test_topic)
    print(content)
